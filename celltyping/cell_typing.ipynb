{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "393ecc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rapieniuta/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, ParameterSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "import umap\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    PrecisionRecallDisplay,\n",
    "    roc_curve\n",
    ")\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.frozen import FrozenEstimator\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tqdm import tqdm  # progress bar\n",
    "\n",
    "CELL_TYPE_MAPPING = {'B': 0, 'BnT': 1, 'CD4': 2, 'CD8': 3, 'DC': 4, 'HLADR': 5, 'MacCD163': 6, 'Mural': 7, 'NK': 8, 'Neutrophil': 9, 'Treg': 10, 'Tumor': 11, 'pDC': 12, 'plasma': 13}\n",
    "CELL_TYPE_MAPPING_REVERSE = {v: k for k, v in CELL_TYPE_MAPPING.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7147fe",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37880f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_evaluation(bootstrap_runs, df_X, df_y, path_to_save=None):\n",
    "    results = {}  # will store everything per bootstrap run\n",
    "\n",
    "    aucs = []\n",
    "    f1s_per_class_ovr = []         # NEW: list of lists (OvR, AUC-style)\n",
    "    f1s_per_class_multiclass = []  # NEW: list of lists (average=None)\n",
    "    accuracies = []\n",
    "    balanced_accuracies = []\n",
    "    macro_f1s = []\n",
    "    weighted_f1s = []\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df_X,\n",
    "        df_y,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=df_y\n",
    "    )\n",
    "    \n",
    "    # Fix an explicit class order for consistent storage\n",
    "    class_names = list(CELL_TYPE_MAPPING.keys())\n",
    "    class_labels = [CELL_TYPE_MAPPING[name] for name in class_names]  # e.g. [0,1,2,...] in your mapping\n",
    "\n",
    "    for i in range(bootstrap_runs):\n",
    "        X_train_bootstrap, y_train_bootstrap = resample(\n",
    "            X_train, y_train,\n",
    "            replace=True,\n",
    "            random_state=i,\n",
    "            stratify=y_train,\n",
    "            n_samples=int(2/3 * len(X_train))\n",
    "        )\n",
    "\n",
    "        clf = LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=42)\n",
    "        clf.fit(X_train_bootstrap, y_train_bootstrap)\n",
    "\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "\n",
    "        # Safe proba indexing (columns correspond to clf.classes_)\n",
    "        proba = clf.predict_proba(X_val)\n",
    "        class_to_col = {c: j for j, c in enumerate(clf.classes_)}\n",
    "\n",
    "        # ---- AUC per class + OvR F1 per class (loop, analogous to AUC) ----\n",
    "        auc_this = []\n",
    "        f1_ovr_this = []\n",
    "\n",
    "        for name, label in zip(class_names, class_labels):\n",
    "            y_true_binary = (y_val == label).astype(int)\n",
    "            y_pred_binary = (y_val_pred == label).astype(int)\n",
    "\n",
    "            y_score = proba[:, class_to_col[label]]\n",
    "            fpr, tpr, _ = roc_curve(y_true_binary, y_score)\n",
    "            auc_this.append(auc(fpr, tpr))\n",
    "\n",
    "            f1_ovr_this.append(f1_score(y_true_binary, y_pred_binary, zero_division=0))\n",
    "\n",
    "        aucs.append(auc_this)\n",
    "        f1s_per_class_ovr.append(f1_ovr_this)\n",
    "\n",
    "        # ---- Multiclass per-class F1 (sklearn’s average=None) ----\n",
    "        # Important: force the same label order as CELL_TYPE_MAPPING\n",
    "        f1_multi_this = f1_score(\n",
    "            y_val,\n",
    "            y_val_pred,\n",
    "            average=None,\n",
    "            labels=class_labels,\n",
    "            zero_division=0\n",
    "        )\n",
    "        f1s_per_class_multiclass.append(f1_multi_this.tolist())\n",
    "\n",
    "        # ---- Global metrics ----\n",
    "        accuracies.append(accuracy_score(y_val, y_val_pred))\n",
    "        balanced_accuracies.append(balanced_accuracy_score(y_val, y_val_pred))\n",
    "        macro_f1s.append(f1_score(y_val, y_val_pred, average=\"macro\", zero_division=0))\n",
    "        weighted_f1s.append(f1_score(y_val, y_val_pred, average=\"weighted\", zero_division=0))\n",
    "\n",
    "    # ---- Save everything ----\n",
    "    results[\"class_names\"] = class_names\n",
    "    results[\"class_labels\"] = class_labels\n",
    "\n",
    "    results[\"auc_per_class\"] = aucs\n",
    "    results[\"f1_per_class_ovr\"] = f1s_per_class_ovr\n",
    "    results[\"f1_per_class_multiclass\"] = f1s_per_class_multiclass\n",
    "\n",
    "    results[\"accuracy\"] = accuracies\n",
    "    results[\"balanced_accuracy\"] = balanced_accuracies\n",
    "    results[\"macro_f1\"] = macro_f1s\n",
    "    results[\"weighted_f1\"] = weighted_f1s\n",
    "    if path_to_save:\n",
    "        np.save(path_to_save, results, allow_pickle=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7957034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval_evaluation(df_X, df_y, path_to_save=None, n_splits=10):\n",
    "    results = {}  # will store everything per fold\n",
    "\n",
    "    aucs = []\n",
    "    f1s_per_class_ovr = []         # list of lists (OvR, AUC-style)\n",
    "    f1s_per_class_multiclass = []  # list of lists (average=None)\n",
    "    accuracies = []\n",
    "    balanced_accuracies = []\n",
    "    macro_f1s = []\n",
    "    weighted_f1s = []\n",
    "\n",
    "    # Fix an explicit class order for consistent storage\n",
    "    class_names = list(CELL_TYPE_MAPPING.keys())\n",
    "    class_labels = [CELL_TYPE_MAPPING[name] for name in class_names]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(df_X, df_y)):\n",
    "        X_train = df_X[train_idx] if hasattr(df_X, \"__getitem__\") else df_X.iloc[train_idx]\n",
    "        X_val   = df_X[val_idx]   if hasattr(df_X, \"__getitem__\") else df_X.iloc[val_idx]\n",
    "        y_train = df_y[train_idx] if hasattr(df_y, \"__getitem__\") else df_y.iloc[train_idx]\n",
    "        y_val   = df_y[val_idx]   if hasattr(df_y, \"__getitem__\") else df_y.iloc[val_idx]\n",
    "\n",
    "        clf = LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "\n",
    "        # Safe proba indexing (columns correspond to clf.classes_)\n",
    "        proba = clf.predict_proba(X_val)\n",
    "        class_to_col = {c: j for j, c in enumerate(clf.classes_)}\n",
    "\n",
    "        # ---- AUC per class + OvR F1 per class (loop, analogous to AUC) ----\n",
    "        auc_this = []\n",
    "        f1_ovr_this = []\n",
    "\n",
    "        for name, label in zip(class_names, class_labels):\n",
    "            y_true_binary = (y_val == label).astype(int)\n",
    "            y_pred_binary = (y_val_pred == label).astype(int)\n",
    "\n",
    "            # If a class is missing from training fold, clf.classes_ won't contain it.\n",
    "            if label not in class_to_col:\n",
    "                auc_this.append(np.nan)\n",
    "                f1_ovr_this.append(f1_score(y_true_binary, y_pred_binary, zero_division=0))\n",
    "                continue\n",
    "\n",
    "            y_score = proba[:, class_to_col[label]]\n",
    "            fpr, tpr, _ = roc_curve(y_true_binary, y_score)\n",
    "            auc_this.append(auc(fpr, tpr))\n",
    "\n",
    "            f1_ovr_this.append(f1_score(y_true_binary, y_pred_binary, zero_division=0))\n",
    "\n",
    "        aucs.append(auc_this)\n",
    "        f1s_per_class_ovr.append(f1_ovr_this)\n",
    "\n",
    "        # ---- Multiclass per-class F1 (sklearn’s average=None) ----\n",
    "        f1_multi_this = f1_score(\n",
    "            y_val,\n",
    "            y_val_pred,\n",
    "            average=None,\n",
    "            labels=class_labels,\n",
    "            zero_division=0\n",
    "        )\n",
    "        f1s_per_class_multiclass.append(f1_multi_this.tolist())\n",
    "\n",
    "        # ---- Global metrics ----\n",
    "        accuracies.append(accuracy_score(y_val, y_val_pred))\n",
    "        balanced_accuracies.append(balanced_accuracy_score(y_val, y_val_pred))\n",
    "        macro_f1s.append(f1_score(y_val, y_val_pred, average=\"macro\", zero_division=0))\n",
    "        weighted_f1s.append(f1_score(y_val, y_val_pred, average=\"weighted\", zero_division=0))\n",
    "\n",
    "    # ---- Save everything ----\n",
    "    results[\"class_names\"] = class_names\n",
    "    results[\"class_labels\"] = class_labels\n",
    "\n",
    "    results[\"auc_per_class\"] = aucs\n",
    "    results[\"f1_per_class_ovr\"] = f1s_per_class_ovr\n",
    "    results[\"f1_per_class_multiclass\"] = f1s_per_class_multiclass\n",
    "\n",
    "    results[\"accuracy\"] = accuracies\n",
    "    results[\"balanced_accuracy\"] = balanced_accuracies\n",
    "    results[\"macro_f1\"] = macro_f1s\n",
    "    results[\"weighted_f1\"] = weighted_f1s\n",
    "\n",
    "    if path_to_save:\n",
    "        np.save(path_to_save, results, allow_pickle=True)\n",
    "\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
